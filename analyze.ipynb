{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcR6sUvXGZdpLYFH9a3ax+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up\n",
        "This section should be interacted with. Use `data_path` to designate the folder where the OpenBARR data is. This folder needs to be formatted beforehand - take a look at the **README** or see `/sample_data/original_data` for an example. Change `output_path` to a folder where you want the graphs and the data used to make them.\n",
        "\n",
        "Here, you will also specify the experimental conditions in `conditions` and days in `days`. This will help the program navigate the files and batch process.\n"
      ],
      "metadata": {
        "id": "-Mlw5rlR8FiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Amy6XHoNeakL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac5afda-988d-4dbe-867b-5d15e5ca43de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import packages we need for analysis and graphing\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# specify where the data is - this should be changed\n",
        "data_path = '/content/drive/MyDrive/0 Revamp/sample_data/original_data'\n",
        "output_path = '/content/drive/MyDrive/0 Revamp/sample_data/output'\n",
        "\n",
        "# specify experimental conditions - this should be changed\n",
        "conditions = ['3EtOH', '25EtOH', '50EtOH', '75EtOH']\n",
        "days = ['D1', 'D2', 'D3']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data\n",
        "We read in and format the OpenBARR data to be more understandable and remove the first second of data in case of initial mistracking."
      ],
      "metadata": {
        "id": "4b3x6oRmH-G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_raw(file_path):\n",
        "  \"\"\"Read an OpenBARR file.\n",
        "\n",
        "  Reads a tab-delimited OpenBARR file and specifies the column names.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  file_path : str\n",
        "    The path to the OpenBARR file.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing the data from the OpenBARR file.\n",
        "  \"\"\"\n",
        "  return pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                     names=['time', 'x', 'y', 'in', 'entry', 'exit'])\n",
        "\n",
        "def adjust_y(df):\n",
        "  \"\"\"Adjust the y-coordinates of an OpenBARR dataframe.\n",
        "\n",
        "  Adjusts the y-coordinates of an OpenBARR dataframe relative to the border of\n",
        "  ROSA and RONSA. Where y >= 0 indicates how far animal is in ROSA while y < 0\n",
        "  indicate how far animal is in RONSA. This adjustment makes the data more\n",
        "  intuitive and easier to analyze.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas.DataFrame\n",
        "    A DataFrame containing the data from the OpenBARR file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  This works under the assumption, in short, that the OpenBARR is set up in the\n",
        "  exact same way. Common problems could be flipped ROSA/RONSA causing RONSA to\n",
        "  be >= 0 and ROSA <0 and camera height differences could change the arbitrary\n",
        "  coordinates, affecting the adjustment for a fly never entering ROSA.\n",
        "  \"\"\"\n",
        "  border = df[df['entry'] == 1]['y']  # get y-coords when fly initially enters ROSA\n",
        "  if len(border) > 0:  # if fly was ever in ROSA\n",
        "    df.loc[:, 'y'] = max(border) - df['y']  # the adjustment\n",
        "  else:  # if the fly never entered ROSA,\n",
        "    df.loc[:, 'y'] = 235 - df['y']  # use upper-bound estimate - see notes\n",
        "\n",
        "def preprocess(file_path):\n",
        "  \"\"\"Preprocess an OpenBARR file.\n",
        "\n",
        "  Reads an OpenBARR file, removes the first second of data, and adjusts the\n",
        "  y-coordinates relative to the border of ROSA and RONSA.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  file_path : str\n",
        "    The path to the OpenBARR file.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing the preprocessed data from the OpenBARR file.\n",
        "  \"\"\"\n",
        "  df = read_raw(file_path)\n",
        "  df = df[df['time'] >= 1]\n",
        "  adjust_y(df)\n",
        "  return df.reset_index(drop=True)\n",
        "\n",
        "def get_bouts(df):\n",
        "  \"\"\"Retrieve bout data for an OpenBARR dataframe.\n",
        "\n",
        "  Extracts bout data to make some analyses easier. A bout is defined as a\n",
        "  continuous portion of time in ROSA or RONSA.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas.DataFrame\n",
        "    A DataFrame containing the preprocessed data from the OpenBARR file.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing bout data.\n",
        "\n",
        "  \"\"\"\n",
        "  # determine where bouts start/end and sort for easy iteration \"bucketing\"\n",
        "  indices = np.sort(np.concatenate([0, np.where(df['entry'] == 1)[0], np.where(df['exit'] == 1)[0], df.shape[0]], axis=None))\n",
        "\n",
        "  bouts = pd.DataFrame(columns=['bout', 'in', 'start', 'end', 'max depth', 'distance'])\n",
        "  for i in range(indices.size-1):\n",
        "    start, end = indices[i], indices[i+1]\n",
        "    if end - start > 1:  # make sure this bout is greater than 1 frame\n",
        "      # get max depth for bout\n",
        "      depth = np.amax(np.abs(df.loc[start:end, 'y']))\n",
        "\n",
        "      # compute total distance traveled in a bout\n",
        "      dist = np.sum(np.linalg.norm(np.subtract(df.iloc[start+1:end][['x', 'y']].reset_index(drop=True),\n",
        "                                                df.iloc[start:end-1][['x', 'y']].reset_index(drop=True)), axis=1))\n",
        "      bouts.loc[bouts.shape[0]] = [i, df.iloc[start]['in'], df.iloc[start]['time'], df.iloc[end-1]['time'], depth, dist]\n",
        "  return bouts\n",
        "\n",
        "# read in all the data and put them into dataframes for analysis\n",
        "combined_df, bouts_df = None, None\n",
        "for condition in conditions:\n",
        "  for day in days:\n",
        "    temp_path = os.path.join(data_path, condition, day)\n",
        "    print('Processing files in', temp_path)\n",
        "    for a_file in os.listdir(temp_path):\n",
        "      temp_df = preprocess(os.path.join(temp_path, a_file))\n",
        "\n",
        "      # take preprocessed file, label, and add to the big preprocessed df\n",
        "      temp_df.loc[:, ['condition', 'day', 'id']] = condition, day, a_file\n",
        "      if combined_df is None:\n",
        "        combined_df = temp_df.copy()\n",
        "      else:\n",
        "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
        "\n",
        "      # take preprocessed file, get bouts, label, and add to bouts df\n",
        "      temp_bouts = get_bouts(temp_df)\n",
        "      temp_bouts.loc[:, ['condition', 'day', 'id']] = condition, day, a_file\n",
        "      if bouts_df is None:\n",
        "        bouts_df = temp_bouts.copy()\n",
        "      else:\n",
        "        bouts_df = pd.concat([bouts_df, temp_bouts], ignore_index=True)\n",
        "\n",
        "    print(len(os.listdir(temp_path)), 'files processed\\n')"
      ],
      "metadata": {
        "id": "u0WU5QRaI1qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphing Time"
      ],
      "metadata": {
        "id": "un-5S2P6O34j"
      }
    }
  ]
}