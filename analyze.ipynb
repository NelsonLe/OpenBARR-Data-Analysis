{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuK83Ovkdr3BNx54lJQ8LM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up\n",
        "This section should be interacted with. Use `data_path` to designate the folder where the OpenBARR data is. This folder needs to be formatted beforehand - take a look at the **README** or see `/sample_data/original_data` for an example. Change `output_path` to a folder where you want the graphs and the data used to make them.\n",
        "\n",
        "Here, you will also specify the experimental conditions in `conditions` and days in `days`. This will help the program navigate the files and batch process.\n"
      ],
      "metadata": {
        "id": "-Mlw5rlR8FiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Amy6XHoNeakL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d359cf9-67fc-44a1-9e99-63bd9f7bd328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import packages we need for analysis and graphing\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['pdf.fonttype'] = 42\n",
        "matplotlib.rcParams['ps.fonttype'] = 42\n",
        "\n",
        "# specify where the data is\n",
        "data_path = '/content/drive/MyDrive/0 Revamp/sample_data/original_data'\n",
        "output_path = '/content/drive/MyDrive/0 Revamp/sample_data/output'\n",
        "\n",
        "# specify experimental conditions\n",
        "conditions = ['3EtOH', '25EtOH', '50EtOH', '75EtOH']\n",
        "days = ['D1', 'D2', 'D3']\n",
        "\n",
        "# specify binning parameters\n",
        "bin_size, total_time = 60, 900\n",
        "bins_array = bin_size*np.arange(total_time/bin_size+1)\n",
        "\n",
        "# specify some aesthetic stuff\n",
        "colors = [\n",
        "    ['#4188C5', '#326EA3', '#26547C'],  # for condition 0, 3EtOH, days 1, 2, and 3\n",
        "    ['#F47C98', '#F16284', '#EF476F'],  # for condition 1, 25Etoh, days 1, 2, and 3\n",
        "    ['#FFDE92', '#FFD87C', '#FFD166'],  # ...\n",
        "    ['#35FAC5', '#0CF9BA', '#06D6A0']\n",
        "  ]\n",
        "\n",
        "# in case you have data preprocessed already\n",
        "# tracking_df = pd.read_csv(os.path.join(output_path, 'tracking_df.csv'))\n",
        "bouts_df = pd.read_csv(os.path.join(output_path, 'bouts_df.csv'))\n",
        "bins_df = pd.read_csv(os.path.join(output_path, 'bins_df.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data\n",
        "We read in and format the OpenBARR data to be more understandable and remove the first second of data in case of initial mistracking."
      ],
      "metadata": {
        "id": "4b3x6oRmH-G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_raw(file_path):\n",
        "  \"\"\"Read an OpenBARR file.\n",
        "\n",
        "  Reads a tab-delimited OpenBARR file and specifies the column names.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  file_path : str\n",
        "    The path to the OpenBARR file.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing the data from the OpenBARR file.\n",
        "  \"\"\"\n",
        "  return pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                     names=['time', 'x', 'y', 'in', 'entry', 'exit'])\n",
        "\n",
        "def adjust_y(df):\n",
        "  \"\"\"Adjust the y-coordinates of an OpenBARR dataframe.\n",
        "\n",
        "  Adjusts the y-coordinates of an OpenBARR dataframe relative to the border of\n",
        "  ROSA and RONSA. Where y >= 0 indicates how far animal is in ROSA while y < 0\n",
        "  indicate how far animal is in RONSA. This adjustment makes the data more\n",
        "  intuitive and easier to analyze.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas.DataFrame\n",
        "    A DataFrame containing the data from the OpenBARR file.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  This works under the assumption, in short, that the OpenBARR is set up in the\n",
        "  exact same way. Common problems could be flipped ROSA/RONSA causing RONSA to\n",
        "  be >= 0 and ROSA <0 and camera height differences could change the arbitrary\n",
        "  coordinates, affecting the adjustment for a fly never entering ROSA.\n",
        "  \"\"\"\n",
        "  border = df[df['entry'] == 1]['y']  # get y-coords when fly initially enters ROSA\n",
        "  if len(border) > 0:  # if fly was ever in ROSA\n",
        "    df.loc[:, 'y'] = max(border) - df['y']  # the adjustment\n",
        "  else:  # if the fly never entered ROSA,\n",
        "    df.loc[:, 'y'] = 235 - df['y']  # use upper-bound estimate - see notes\n",
        "\n",
        "def preprocess(file_path):\n",
        "  \"\"\"Preprocess an OpenBARR file.\n",
        "\n",
        "  Reads an OpenBARR file, removes the first second of data, and adjusts the\n",
        "  y-coordinates relative to the border of ROSA and RONSA.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  file_path : str\n",
        "    The path to the OpenBARR file.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing the preprocessed data from the OpenBARR file.\n",
        "  \"\"\"\n",
        "  df = read_raw(file_path)\n",
        "  df = df[df['time'] >= 1]\n",
        "  adjust_y(df)\n",
        "  return df.reset_index(drop=True)\n",
        "\n",
        "def get_bouts(df, bins=None):\n",
        "  \"\"\"Retrieve bout data for an OpenBARR dataframe.\n",
        "\n",
        "  Extracts bout data to make some analyses easier. A bout is defined as a\n",
        "  continuous portion of time in ROSA or RONSA.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas.DataFrame\n",
        "    A DataFrame containing the preprocessed data from the OpenBARR file.\n",
        "  bins : np.array, optional\n",
        "    A list containing the bins to further split the data\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pandas.DataFrame\n",
        "    A DataFrame containing bout data.\n",
        "\n",
        "  \"\"\"\n",
        "  # normalizer to convert OpenBARR's arbitrary coordinates to cm\n",
        "  normalizer = 50\n",
        "\n",
        "  # determine where bouts start/end and sort for easy iteration\n",
        "  indices = None\n",
        "  if bins is None:\n",
        "    indices = np.sort(np.unique(np.concatenate([0, np.where(df['entry'] == 1)[0], np.where(df['exit'] == 1)[0], df.shape[0]-1], axis=None)))\n",
        "  else:\n",
        "    indices = np.sort(np.unique(np.concatenate([np.where(df['entry'] == 1)[0],\n",
        "                                                np.where(df['exit'] == 1)[0],\n",
        "                                                [np.where((df['time'].reset_index(drop=True) - bin) >= 0)[0][0] for bin in bins],\n",
        "                                                df.shape[0]-1], axis=None)))\n",
        "\n",
        "  bout_indicator, bout_num = df.loc[indices[0], 'in'], 0\n",
        "  running_max_depth, running_sample_timer = 0, 0\n",
        "  bouts = pd.DataFrame(columns=['bout', 'in', 'start', 'end', 'duration', 'max depth', 'distance', 'speed', 'entry', 'sample'])\n",
        "  for i in range(indices.size-1):\n",
        "    # where this bout starts and ends\n",
        "    start, end = indices[i], indices[i+1]\n",
        "\n",
        "    # where next bout starts and ends\n",
        "    next_start, next_end, future_bout_indicator = None, None, None\n",
        "    if i+1 < indices.size-1:\n",
        "      next_start, next_end = indices[i+1], indices[i+2]\n",
        "      future_bout_indicator = df.loc[next_start, 'in']\n",
        "\n",
        "    # get data on whether this bout was in ROSA or RONSA\n",
        "    in_rosa = df.loc[start, 'in']\n",
        "\n",
        "    # reset data on past bouts if this is a new bout in a new region\n",
        "    if bout_indicator != in_rosa:\n",
        "      bout_num += 1  # track bouts by change in region, not change in bins\n",
        "      bout_indicator = in_rosa  # update prev. bout indicator for next bout\n",
        "      running_max_depth, running_sample_timer = 0, 0  # reset previous depth and sample data\n",
        "\n",
        "    # compute bout duration\n",
        "    start_time, end_time = df.loc[start, 'time'], df.loc[end-1, 'time']\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    # get max depth for bout\n",
        "    depth = np.max([np.max(np.abs(df.loc[start:end, 'y']))/normalizer,  # max depth for this bout\n",
        "                    running_max_depth,  # max depth for previous bout, non-zero when previous bout was in same region\n",
        "                    np.max(np.abs(df.loc[next_start:next_end, 'y']))/normalizer if future_bout_indicator == in_rosa else 0])  # max depth for future bout, non-zero if future bout is in same region\n",
        "    running_max_depth = depth  # update the prev. depth for next bout\n",
        "\n",
        "    # compute total distance traveled in a bout\n",
        "    dist = np.sum(np.linalg.norm(np.subtract(df.iloc[start+1:end][['x', 'y']].reset_index(drop=True),\n",
        "                                              df.iloc[start:end-1][['x', 'y']].reset_index(drop=True)),\n",
        "                                  axis=1))/normalizer\n",
        "\n",
        "    # compute speed for a bout\n",
        "    speed = dist/duration if duration > 0 else 0\n",
        "\n",
        "    # determine if this bout was an entry\n",
        "    entry = 1 if in_rosa == 1 and i != 0 else 0\n",
        "\n",
        "    # determine if this bout was a sample\n",
        "    future_bout_time = df.loc[next_end-1, 'time'] - df.loc[next_start, 'time'] if future_bout_indicator == in_rosa else 0  # compute time for next bout if in same region\n",
        "    sample = 1 if duration + running_sample_timer + future_bout_time <= 2 and in_rosa == 1 else 0  # sample if duration of this bout summed with the duration of the next/past bouts that are also in same region, is less 2 seconds\n",
        "    running_sample_timer = duration  # update the prev. sample timer for next bout\n",
        "\n",
        "    # create row for this bout\n",
        "    bouts.loc[bouts.shape[0]] = [bout_num, in_rosa, start_time, end_time, duration, depth, dist, speed, entry, sample]\n",
        "  return bouts\n",
        "\n",
        "def get_quantiles(bouts_data, conditions, day=days[-1], rosa=1, target_col='duration', agg_func='sum', n_c=4, labels=None):\n",
        "  \"\"\"Get quantiles for bouts data.\n",
        "\n",
        "  Assigns and returns quantiles bouts data. Which conditions, the day, rosa,\n",
        "  target column, and aggregate function are specified. Default settings are\n",
        "  quartiles for flies that are in ROSA the most in the last day.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  bouts_data : pandas.DataFrame\n",
        "    A DataFrame containing bout data created in the \"Preprocess the data\" step\n",
        "  conditions : list\n",
        "    A list of condition names specified initially\n",
        "  day : str, default = days[-1]\n",
        "    The day to get the quantiles for, default is last day\n",
        "  rosa : int, default = 1\n",
        "    1 (meaning in ROSA) or 0 (meaning in RONSA)\n",
        "  target_col : str, default = 'duration'\n",
        "    The name of the column of interest from the bouts data\n",
        "  agg_func : str, default = 'sum'\n",
        "    The name of a pandas aggregate function like \"sum\" and \"mean\"\n",
        "  n_c : int, default = 4\n",
        "    How many quantiles you want to split the data into\n",
        "  labels : list, default = None\n",
        "    The names you want to assign to the quantiles\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  bouts_data : pandas.DataFrame\n",
        "    A DataFrame containing bout data with quantiles assigned\n",
        "  q_df : pandas.DataFrame\n",
        "    A DataFrame containing quantiles for reference\n",
        "  \"\"\"\n",
        "  # filter bouts data by day to get the data used to determine quartiles\n",
        "  filtered_df = bouts_data[(bouts_data['day'] == day) & (bouts_data['in'] == rosa)]\n",
        "\n",
        "  # aggregate the filtered data\n",
        "  agg_df = filtered_df.groupby(['condition', 'id']).agg({target_col:agg_func})\n",
        "\n",
        "  # get bins and assign quantiles for each condition\n",
        "  q_df = None\n",
        "  for condition in conditions:\n",
        "    assignments, bins = pd.qcut(agg_df.loc[condition, target_col], n_c, labels=labels, retbins=True)\n",
        "    assigned_q = pd.DataFrame({'condition':condition, 'id':agg_df.loc[condition].index, 'quantile':assignments}).reset_index(drop=True)\n",
        "\n",
        "    if q_df is None:\n",
        "      q_df = assigned_q\n",
        "    else:\n",
        "      q_df = pd.concat([q_df, assigned_q], ignore_index=True)\n",
        "\n",
        "  # this next part my not be necessary for you\n",
        "  # because of past naming conventions we process id to match with the ids from other days\n",
        "  # process the new built quantile dataset\n",
        "  q_df['id'] = q_df['id'].str[:-7]\n",
        "\n",
        "  # process bouts_data id column\n",
        "  bouts_data = bouts_data.copy()\n",
        "  bouts_data['id'] = bouts_data['id'].str[:-7]\n",
        "\n",
        "  # assign the quantiles to bouts data\n",
        "  bouts_data = bouts_data.merge(q_df[['condition', 'id', 'quantile']], on=['condition', 'id'], how='left')\n",
        "\n",
        "  return bouts_data, q_df"
      ],
      "metadata": {
        "id": "u0WU5QRaI1qf"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the data and put them into dataframes for analysis\n",
        "tracking_df, bouts_df, bins_df = None, None, None\n",
        "for condition in conditions:\n",
        "  for day in days:\n",
        "    temp_path = os.path.join(data_path, condition, day)\n",
        "    print('Processing files in', temp_path)\n",
        "    for a_file in os.listdir(temp_path):\n",
        "      temp_df = preprocess(os.path.join(temp_path, a_file)).reset_index(drop=True)\n",
        "\n",
        "      # take preprocessed file, label, and add to the big preprocessed df\n",
        "      temp_df.loc[:, ['condition', 'day', 'id']] = condition, day, a_file\n",
        "      if tracking_df is None:\n",
        "        tracking_df = temp_df.copy()\n",
        "      else:\n",
        "        tracking_df = pd.concat([tracking_df, temp_df], ignore_index=True)\n",
        "\n",
        "      # take preprocessed file, get bouts, label, and add to bouts df\n",
        "      temp_bouts = get_bouts(temp_df)\n",
        "      temp_bouts.loc[:, ['condition', 'day', 'id']] = condition, day, a_file\n",
        "      if bouts_df is None:\n",
        "        bouts_df = temp_bouts.copy()\n",
        "      else:\n",
        "        bouts_df = pd.concat([bouts_df, temp_bouts], ignore_index=True)\n",
        "\n",
        "      # take preprocessed file, get bouts, label, and add to bouts df\n",
        "      temp_bins = get_bouts(temp_df, bins=bins_array[:-1])\n",
        "      temp_bins.loc[:, ['condition', 'day', 'id']] = condition, day, a_file\n",
        "      if bouts_df is None:\n",
        "        bins_df = temp_bins.copy()\n",
        "      else:\n",
        "        bins_df = pd.concat([bins_df, temp_bins], ignore_index=True)\n",
        "\n",
        "    print(len(os.listdir(temp_path)), 'files processed\\n')\n",
        "\n",
        "# optional - assign bouts data to quantiles and returns the quantiles for reference\n",
        "bouts_df, quantiles = get_quantiles(bouts_df, conditions)\n",
        "\n",
        "# uncomment below if you want to save newly built dfs for reference\n",
        "# tracking_df.to_csv(os.path.join(output_path, 'tracking_df.csv'), index=False)\n",
        "bouts_df.to_csv(os.path.join(output_path, 'bouts_df.csv'), index=False)\n",
        "bins_df.to_csv(os.path.join(output_path, 'bins_df.csv'), index=False)"
      ],
      "metadata": {
        "id": "19EehQK5GMFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph the data"
      ],
      "metadata": {
        "id": "un-5S2P6O34j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scatter Bar Plots\n",
        "\n"
      ],
      "metadata": {
        "id": "7J9lW33rBFNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_bar_plot(bouts_data, conditions, days, rosa, target_col, agg_func, colors, ylim_top=None, ylab='default ylab', plot_title='default title'):\n",
        "  \"\"\"Create a scatter bar plot.\n",
        "\n",
        "  Creates a scatter bar plot using bout data. The data plotted is specified by\n",
        "  commonly analyzed variables such as when the fly is in ROSA, bout duration,\n",
        "  distance traveled, etc. Aggregate functions can also be specified and are used\n",
        "  to summarize your variable of interest. Data used to produce the graph is\n",
        "  outputed and a pdf of the graph is saved to your specified output path.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  bouts_data : pandas.DataFrame\n",
        "    A DataFrame containing bout data created in the \"Preprocess the data\" step\n",
        "  conditions : list\n",
        "    A list of condition names specified initially\n",
        "  days : list\n",
        "    A list of day names specified initially\n",
        "  rosa : int\n",
        "    1 (meaning in ROSA) or 0 (meaning in RONSA)\n",
        "  target_col : str\n",
        "    The name of the column of interest from the bouts data\n",
        "  agg_func : str\n",
        "    The name of a pandas aggregate function like \"sum\" and \"mean\"\n",
        "  colors : list\n",
        "    2d list of colors to use for each condition and day\n",
        "  ylim_top : int, default = None\n",
        "    The max value of the y-axis for the plot\n",
        "  ylab : str, default = 'default ylab'\n",
        "    The y-axis label\n",
        "  plot_title : str, default = 'default title'\n",
        "    The title of the plot - also used to name the output files\n",
        "  \"\"\"\n",
        "  # variables for plot transparency, width of columns, and angle of x labels\n",
        "  t, w, ang = 0.8, 0.25, 20\n",
        "\n",
        "  # create the grid for the multiple plots\n",
        "  fig, ax = plt.subplots(1, len(days), sharey=True, figsize=(2*len(days), 6))\n",
        "  x = np.arange(len(conditions))*w\n",
        "\n",
        "  # aggregate data for graphing\n",
        "  agg_bouts_df = bouts_data.groupby(['condition', 'day', 'in', 'id']).agg({target_col:agg_func})\n",
        "\n",
        "  for i, day in enumerate(days):\n",
        "    for j, condition in enumerate(conditions):\n",
        "      # select condition, day, and rosa from the aggregated data\n",
        "      temp_data = agg_bouts_df.loc[(condition, day, rosa)]\n",
        "\n",
        "      # use the selected data to scatter plot a single \"bar\"\n",
        "      ax[i].scatter(j*w+np.random.uniform(-0.05, 0.05, len(temp_data)), temp_data, color=colors[j][i], alpha=t)\n",
        "\n",
        "    # labeling and aesthetic for a day's particular graph\n",
        "    ax[i].set_xticks(x, labels=conditions, rotation=ang)\n",
        "    ax[i].set_title(day)\n",
        "    ax[i].spines[['right', 'top']].set_visible(False)\n",
        "\n",
        "  # more labeling and standardizing of yaxis\n",
        "  ax[0].set_ylim(0, ylim_top)\n",
        "  ax[0].set_ylabel(ylab)\n",
        "  fig.suptitle(plot_title)\n",
        "\n",
        "  # save the data used for graphing\n",
        "  save = agg_bouts_df.reset_index()\n",
        "  save.to_csv(os.path.join(output_path, f'{plot_title}.csv'), index=False)\n",
        "\n",
        "  # save figure\n",
        "  fig.savefig(os.path.join(output_path, f'{plot_title}.pdf'), transparent=True)"
      ],
      "metadata": {
        "id": "NjV41ZmDBG82"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Scatter Bar Plots"
      ],
      "metadata": {
        "id": "gtzsN52f9CLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# time\n",
        "# total time spent in rosa/ronsa\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='duration', agg_func='sum',\n",
        "                 colors=colors, ylab='s', plot_title='Total Time Spent in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='duration', agg_func='sum',\n",
        "                 colors=colors, ylab='s', plot_title='Total Time Spent in RONSA')\n",
        "\n",
        "# average time spent in rosa/ronsa, i also specify ylim_top in the rosa case \\\n",
        "# if you need to change the max value of the y-axis\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='duration', agg_func='mean', ylim_top=50,\n",
        "                 colors=colors, ylab='s', plot_title='Average Time Spent in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='duration', agg_func='mean',\n",
        "                 colors=colors, ylab='s', plot_title='Average Time Spent in RONSA')\n",
        "\n",
        "# distance\n",
        "# total distance traveled in rosa/ronsa\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='distance', agg_func='sum',\n",
        "                 colors=colors, ylab='cm', plot_title='Total Distance Traveled in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='distance', agg_func='sum',\n",
        "                 colors=colors, ylab='cm', plot_title='Total Distance Traveled in RONSA')\n",
        "\n",
        "# average distance traveled in rosa/ronsa\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='distance', agg_func='mean',\n",
        "                 colors=colors, ylab='cm', plot_title='Average Distance Traveled in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='distance', agg_func='mean',\n",
        "                 colors=colors, ylab='cm', plot_title='Average Distance Traveled in RONSA')\n",
        "\n",
        "# average speed across bouts\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='speed', agg_func='mean',\n",
        "                 colors=colors, ylab='cm/s', plot_title='Average Speed in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='speed', agg_func='mean',\n",
        "                 colors=colors, ylab='cm/s', plot_title='Average Speed in RONSA')\n",
        "\n",
        "# total entries to rosa\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='entry', agg_func='sum',\n",
        "                 colors=colors, ylab='Entries', plot_title='Total Entries to ROSA')\n",
        "\n",
        "# average max depth in rosa/ronsa, set ylim_top=4 for alignment with openbarr\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='max depth', agg_func='mean', ylim_top=4,\n",
        "                 colors=colors, ylab='cm', plot_title='Average Depth in ROSA')\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=0, target_col='max depth', agg_func='mean', ylim_top=4,\n",
        "                 colors=colors, ylab='cm', plot_title='Average Depth in RONSA')\n",
        "\n",
        "# samples\n",
        "scatter_bar_plot(bouts_df, conditions, days, rosa=1, target_col='sample', agg_func='sum',\n",
        "                 colors=colors, ylab='Samples', plot_title='Total Samples')"
      ],
      "metadata": {
        "id": "8V1FcU4DRft8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Behavior Across Time Plots"
      ],
      "metadata": {
        "id": "l98PfGBKAHiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add bins to the bins df beforehand\n",
        "bins_df['bin'] = pd.cut(bins_df['start'], bins_array, labels=np.arange(total_time/bin_size)+1)\n",
        "\n",
        "def beh_time_plot(bins_data, bins, conditions, days, rosa, target_col, agg_func,\n",
        "                  colors, ylims=(None, None), ylab='default ylab', plot_title='default title'):\n",
        "  \"\"\"Create two plots - one across conditions and another across days.\n",
        "\n",
        "  Creates a behavior across time plot using binned data. The data plotted is\n",
        "  specified by commonly analyzed variables such as when the fly is in ROSA,\n",
        "  duration of bout, etc. Aggregate functions can also be specified and are used\n",
        "  to summarize your variable of interest. Data used to produce the graph is\n",
        "  outputed and a pdf of the graph is saved to your specified output path.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  bins_data : pandas.DataFrame\n",
        "    A DataFrame containing binned data created in the \"Preprocess the data\"\n",
        "    step with bins added beforehand\n",
        "  bins : np.array\n",
        "    An array of bin edges\n",
        "  conditions : list\n",
        "    A list of condition names specified initially\n",
        "  days : list\n",
        "    A list of day names specified initially\n",
        "  rosa : int\n",
        "    1 (meaning in ROSA) or 0 (meaning in RONSA)\n",
        "  target_col : str\n",
        "    The name of the column of interest from the bins data\n",
        "  agg_func : str\n",
        "    The name of a pandas aggregate function\n",
        "  colors : list\n",
        "    2d list of colors to use for each condition and day\n",
        "  ylims : tuple, default = (None, None)\n",
        "    The min and max values of the y-axis\n",
        "  ylab : str, default = 'default ylab'\n",
        "    The y-axis label\n",
        "  plot_title : str, default = 'default title'\n",
        "    The title of the plot - also used to name the output files\n",
        "  \"\"\"\n",
        "  # set up x-axis for plotting\n",
        "  x = np.arange(total_time/bin_size) + 1\n",
        "\n",
        "  # aggregate data for graphing\n",
        "  agg_bins_df = bins_data.groupby(['condition', 'day', 'in', 'bin', 'id'], observed=True).agg({target_col:agg_func})\n",
        "\n",
        "  #-----plots where each individual plot is for a day-----\n",
        "  # create the grid for the multiple plots with a grid for each day\n",
        "  fig, ax = plt.subplots(1, len(days), sharey=True, figsize=(8*len(days), 4.5))\n",
        "  for i, day in enumerate(days):\n",
        "    for j, condition in enumerate(conditions):\n",
        "      # select condition, day, and rosa from the aggregated data\n",
        "      temp_data = agg_bins_df.loc[(condition, day, rosa)].reset_index().groupby('bin', observed=True).agg({target_col:'mean'}).sort_index()\n",
        "      temp_se = agg_bins_df.loc[(condition, day, rosa)].reset_index().groupby('bin', observed=True).agg({target_col:'sem'}).sort_index()\n",
        "\n",
        "      # use the selected data to plot a single line for a condition and day\n",
        "      ax[i].plot(x, temp_data, label=condition, color=colors[j][i])\n",
        "\n",
        "      # plot error bars\n",
        "      error_lb, error_ub = (temp_data-temp_se)[target_col], (temp_data+temp_se)[target_col]\n",
        "      ax[i].fill_between(error_lb.index, error_lb, error_ub, color=colors[j][i], alpha=0.2)\n",
        "\n",
        "    # labeling and aesthetic for a day's particular graph\n",
        "    ax[i].set_xticks(x)\n",
        "    ax[i].set_xlim(x[0], x[-1])\n",
        "    ax[i].set_title(day)\n",
        "    ax[i].spines[['right', 'top']].set_visible(False)\n",
        "  # more labeling and standardizing of yaxis\n",
        "  ax[0].set_ylim(ylims)\n",
        "  ax[0].set_ylabel(ylab)\n",
        "  ax[0].legend()\n",
        "  fig.suptitle(plot_title)\n",
        "  # save figure\n",
        "  fig.savefig(os.path.join(output_path, f'{plot_title} By Condition.pdf'), transparent=True)\n",
        "\n",
        "  #-----plots where each individual plot is for a condition-----\n",
        "  # create grid for multiple plots with a grid for each condition\n",
        "  fig, ax = plt.subplots(1, len(conditions), sharey=True, figsize=(8*len(conditions), 4.5))\n",
        "  for j, condition in enumerate(conditions):\n",
        "    for i, day in enumerate(days):\n",
        "      # select condition, day, and rosa from the aggregated data\n",
        "      temp_data = agg_bins_df.loc[(condition, day, rosa)].reset_index().groupby('bin', observed=True).agg({target_col:'mean'}).sort_index()\n",
        "      temp_se = agg_bins_df.loc[(condition, day, rosa)].reset_index().groupby('bin', observed=True).agg({target_col:'sem'}).sort_index()\n",
        "\n",
        "      # use the selected data to plot a single line for a condition and day\n",
        "      ax[j].plot(x, temp_data, label=day, color=colors[j][i], linestyle=(0, ((i+1)**2, i)))\n",
        "\n",
        "      # plot error bars\n",
        "      error_lb, error_ub = (temp_data-temp_se)[target_col], (temp_data+temp_se)[target_col]\n",
        "      ax[j].fill_between(error_lb.index, error_lb, error_ub, color=colors[j][i], alpha=0.2)\n",
        "\n",
        "    # labeling and aesthetic for a day's particular graph\n",
        "    ax[j].set_xticks(x)\n",
        "    ax[j].set_xlim(x[0], x[-1])\n",
        "    ax[j].set_title(condition)\n",
        "    ax[j].spines[['right', 'top']].set_visible(False)\n",
        "    ax[j].legend()\n",
        "  # more labeling and standardizing of yaxis\n",
        "  ax[0].set_ylim(ylims)\n",
        "  ax[0].set_ylabel(ylab)\n",
        "  fig.suptitle(plot_title)\n",
        "  # save figure\n",
        "  fig.savefig(os.path.join(output_path, f'{plot_title} By Day.pdf'), transparent=True)\n",
        "\n",
        "  # save the data used for graphing\n",
        "  save = agg_bins_df.reset_index()\n",
        "  save.to_csv(os.path.join(output_path, f'{plot_title}.csv'), index=False)"
      ],
      "metadata": {
        "id": "_vaYAiUV2tUg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time in rosa/ronsa\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=1,\n",
        "              target_col='duration', agg_func='sum', colors=colors,\n",
        "              ylab='seconds', plot_title='Time Spent in ROSA')\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=0,\n",
        "              target_col='duration', agg_func='sum', colors=colors,\n",
        "              ylab='seconds', plot_title='Time Spent in RONSA')\n",
        "\n",
        "# velocity in rosa/ronsa\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=1,\n",
        "              target_col='speed', agg_func='mean', colors=colors,\n",
        "              ylab='cm/s', plot_title='Average Speed in ROSA')\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=0,\n",
        "              target_col='speed', agg_func='mean', colors=colors,\n",
        "              ylab='cm/s', plot_title='Average Speed in RONSA')\n",
        "\n",
        "# distance moved in rosa/ronsa\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=1,\n",
        "              target_col='distance', agg_func='sum', colors=colors,\n",
        "              ylab='cm', plot_title='Distance Traveled in ROSA')\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=0,\n",
        "              target_col='distance', agg_func='sum', colors=colors,\n",
        "              ylab='cm', plot_title='Distance Traveled in RONSA')\n",
        "\n",
        "# depth in rosa/ronsa\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=1,\n",
        "              target_col='max depth', agg_func='mean', colors=colors,\n",
        "              ylab='cm', plot_title='Average Depth in ROSA')\n",
        "beh_time_plot(bins_df, bins_array, conditions, days, rosa=0,\n",
        "              target_col='max depth', agg_func='mean', colors=colors,\n",
        "              ylab='cm', plot_title='Average Depth in RONSA')"
      ],
      "metadata": {
        "id": "BZLHuEy65omu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scatter Bar Plots w/ Binning"
      ],
      "metadata": {
        "id": "Z-cOYlWHy5QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_bar_plot_binned(bouts_data, conditions, days, rosa, target_col,\n",
        "                            agg_func, colors, ylim_top=None, ylab='default ylab',\n",
        "                            plot_title='default title'):\n",
        "  \"\"\"Create a scatter bar plot but split up further.\n",
        "\n",
        "  Creates a scatter bar plot using bout data that has a binned data column.\n",
        "  Binning is done before calling this function. The data plotted can be\n",
        "  by the bout variables and an aggregate function. However, this has only been\n",
        "  used to count the number of bouts of certain durations.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  bouts_data : pandas.DataFrame\n",
        "    A DataFrame containing bout data created in the \"Preprocess the data\"\n",
        "    step with bins added beforehand\n",
        "  conditions : list\n",
        "    A list of condition names specified initially\n",
        "  days : list\n",
        "    A list of day names specified initially\n",
        "  rosa : int\n",
        "    1 (meaning in ROSA) or 0 (meaning in RONSA)\n",
        "  target_col : str\n",
        "    The name of the column of interest from the bouts data\n",
        "  agg_func : str\n",
        "    The name of a pandas aggregate function like \"sum\" and \"mean\"\n",
        "  colors : list\n",
        "    2d list of colors to use for each condition and day\n",
        "  ylim_top : int, default = None\n",
        "    The max value of the y-axis for the plot\n",
        "  ylab : str, default = 'default ylab'\n",
        "    The y-axis label\n",
        "  plot_title : str, default = 'default title'\n",
        "    The title of the plot - also used to name the output files\n",
        "  \"\"\"\n",
        "\n",
        "  # variables for plot transparency, width of columns, and angle of x labels\n",
        "  t, w, ang = 0.8, 0.25, 20\n",
        "\n",
        "  # create the grid for the multiple plots\n",
        "  bins = bouts_data['general bins'].sort_values().unique()\n",
        "  fig, ax = plt.subplots(1, len(days), sharey=True, figsize=(len(conditions)*len(days)*2, 6))\n",
        "  x = np.arange(len(bins))*len(conditions)/2  # multiplied by half the number of conditions to ensure enough space between each bin\n",
        "\n",
        "  # aggregate data for graphing\n",
        "  agg_bouts_df = bouts_data.groupby(['condition', 'day', 'in', 'general bins', 'id'], observed=True).agg({target_col:agg_func})\n",
        "\n",
        "  for i, day in enumerate(days):\n",
        "    for j, condition in enumerate(conditions):\n",
        "      for k, bin in enumerate(bins):\n",
        "        # select condition, day, and rosa from the aggregated data\n",
        "        temp_data = agg_bouts_df.loc[(condition, day, rosa, bin)]\n",
        "\n",
        "        # use the selected data to scatter plot a single \"bar\"\n",
        "        ax[i].scatter(x[k]+j*w+np.random.uniform(-0.05, 0.05, len(temp_data)), temp_data, color=colors[j][i], alpha=t)\n",
        "\n",
        "    # labeling and aesthetic for a day's particular graph\n",
        "    ax[i].set_xticks(x+(w*len(conditions)/2), labels=bins, rotation=ang)\n",
        "    ax[i].set_title(day)\n",
        "    ax[i].spines[['right', 'top']].set_visible(False)\n",
        "\n",
        "  # more labeling and standardizing of yaxis\n",
        "  ax[0].set_ylim(0, ylim_top)\n",
        "  ax[0].set_ylabel(ylab)\n",
        "  fig.suptitle(plot_title)\n",
        "\n",
        "  # save the data used for graphing\n",
        "  save = agg_bouts_df.reset_index()\n",
        "  save.to_csv(os.path.join(output_path, f'{plot_title}.csv'), index=False)\n",
        "\n",
        "  # save figure\n",
        "  fig.savefig(os.path.join(output_path, f'{plot_title}.pdf'), transparent=True)"
      ],
      "metadata": {
        "id": "at-QA8_8FmgL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# general binning - current use is binning by bout duration but can be easily changed to break down data in your own way\n",
        "general_bins = [0, 2, 5, 10, 15, 20, 25, 30, float('inf')]  # currently set for duration\n",
        "bouts_df['general bins'] = pd.cut(bouts_df['duration'], bins=general_bins, include_lowest=True)  # bin duration column\n",
        "\n",
        "# target_col can be anything here since we're just counting up the amount of instances a bin has\n",
        "scatter_bar_plot_binned(bouts_df, conditions, days, rosa=1, target_col='duration',\n",
        "                        agg_func='count', colors=colors, ylab='count',\n",
        "                        plot_title='ROSA Bouts Per Duration')"
      ],
      "metadata": {
        "id": "SQQ45-elzCBF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}